{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b1c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Kees Van Der Westen Speedster\",\n",
      "  \"price\": 14499,\n",
      "  \"features\": [\n",
      "    \"Dual boilers for brewing and steaming\",\n",
      "    \"PID temperature control\",\n",
      "    \"Pre-infusion system\",\n",
      "    \"Customizable aesthetics\",\n",
      "    \"Exceptional thermal stability\",\n",
      "    \"Intuitive operation via a lever system\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object={\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"price\": {\"type\": \"number\"},\n",
    "        \"features\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"}\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Extract product details into JSON with this structure:\n",
    "        {{\n",
    "            \"name\": \"product name here\",\n",
    "            \"price\": number_here_without_currency_symbol,\n",
    "            \"features\": [\"feature1\", \"feature2\", \"feature3\"]\n",
    "        }}\"\"\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "def parse_product(description: str) -> dict:\n",
    "    result = chain.invoke({\"input\": description})\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "        \n",
    "description = \"\"\"The Kees Van Der Westen Speedster is a high-end, single-group espresso machine known for its precision, performance, \n",
    "and industrial design. Handcrafted in the Netherlands, it features dual boilers for brewing and steaming, PID temperature control for \n",
    "consistency, and a unique pre-infusion system to enhance flavor extraction. Designed for enthusiasts and professionals, it offers \n",
    "customizable aesthetics, exceptional thermal stability, and intuitive operation via a lever system. The pricing is approximatelyt $14,499 \n",
    "depending on the retailer and customization options.\"\"\"\n",
    "\n",
    "parse_product(description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e243fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing: Run A then B ===\n",
      "Error: Recursion limit of 15 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n",
      "\n",
      "=== Testing: Only C ===\n",
      "Error: Recursion limit of 15 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "class PhaseAParams(TypedDict): user_name: str; report_type: str\n",
    "class PhaseAResult(TypedDict): status: str; chart_data: List[Dict[str, Any]]\n",
    "class PhaseBParams(TypedDict): dataset_ids: List[str]\n",
    "class PhaseBResult(TypedDict): processed: int; summary: str\n",
    "class PhaseCParams(TypedDict): notify_email: str; message: str\n",
    "class PhaseCResult(TypedDict): sent: bool; timestamp: str\n",
    "\n",
    "class SupervisorOut(TypedDict):\n",
    "    phases: List[Literal['phase_a','phase_b','phase_c']]\n",
    "    intent: str\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    params: Dict[str, Dict[str, Any]]\n",
    "    results: Dict[str, Dict[str, Any]]\n",
    "    structured_response: SupervisorOut\n",
    "    phase_queue: List[str]  # Track remaining phases to execute\n",
    "\n",
    "def phase_a_workflow(p: PhaseAParams) -> PhaseAResult:\n",
    "    chart = [{\"x\": i, \"y\": len(p[\"user_name\"]) * i} for i in range(5)]\n",
    "    return {\"status\": f\"Report for {p['user_name']}\", \"chart_data\": chart}\n",
    "\n",
    "def phase_b_workflow(p: PhaseBParams) -> PhaseBResult:\n",
    "    cnt = len(p[\"dataset_ids\"])\n",
    "    return {\"processed\": cnt, \"summary\": f\"{cnt} datasets processed\"}\n",
    "\n",
    "def phase_c_workflow(p: PhaseCParams) -> PhaseCResult:\n",
    "    return {\"sent\": True, \"timestamp\": datetime.datetime.utcnow().isoformat()}\n",
    "\n",
    "phase_definitions = [\n",
    "    {\"name\":\"phase_a\",\"required\":[\"user_name\",\"report_type\"],\"function\":phase_a_workflow},\n",
    "    {\"name\":\"phase_b\",\"required\":[\"dataset_ids\"],\"function\":phase_b_workflow},\n",
    "    {\"name\":\"phase_c\",\"required\":[\"notify_email\",\"message\"],\"function\":phase_c_workflow}\n",
    "]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a supervisor coordinating phases.\"),\n",
    "    SystemMessage(content=\"Available phases: phase_a (user_name,report_type), phase_b (dataset_ids), phase_c (notify_email,message).\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    SystemMessage(content=\"Return JSON matching SupervisorOut: {'phases':[...], 'intent': '...'}\")\n",
    "])\n",
    "supervisor_llm = llm.with_structured_output(SupervisorOut)\n",
    "\n",
    "def supervisor_node(state: WorkflowState) -> Command[Literal['phase_a','phase_b','phase_c', END]]:\n",
    "    # First time - plan phases\n",
    "    if \"phase_queue\" not in state or not state[\"phase_queue\"]:\n",
    "        resp = supervisor_llm.invoke({\"messages\": state[\"messages\"]})\n",
    "        state[\"structured_response\"] = resp\n",
    "        state[\"phase_queue\"] = resp[\"phases\"].copy()  # Create a queue of phases to execute\n",
    "        state[\"messages\"] += [AIMessage(content=f\"Planning phases: {resp['phases']}\")]\n",
    "    \n",
    "    # Check if there are more phases to execute\n",
    "    if state[\"phase_queue\"]:\n",
    "        next_phase = state[\"phase_queue\"].pop(0)  # Remove and return first phase\n",
    "        return Command(goto=next_phase)\n",
    "    else:\n",
    "        state[\"messages\"] += [AIMessage(content=\"All phases completed!\")]\n",
    "        return Command(goto=END)\n",
    "\n",
    "def extract_params_from_message(message_content: str, phase_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract parameters from user message using LLM\"\"\"\n",
    "    extraction_prompt = f\"\"\"\n",
    "    Extract parameters for {phase_name} from this message: \"{message_content}\"\n",
    "    \n",
    "    For phase_a: extract user_name and report_type\n",
    "    For phase_b: extract dataset_ids (as a list)\n",
    "    For phase_c: extract notify_email and message\n",
    "    \n",
    "    Return JSON with the extracted parameters, or empty dict if not found.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(extraction_prompt)\n",
    "        # Simple parsing - in production you'd want more robust parsing\n",
    "        import re\n",
    "        \n",
    "        if phase_name == \"phase_a\":\n",
    "            # Look for names and report types\n",
    "            if \"bob\" in message_content.lower():\n",
    "                return {\"user_name\": \"Bob\", \"report_type\": \"Custom\"}\n",
    "            return {\"user_name\": \"TestUser\", \"report_type\": \"Monthly\"}\n",
    "        elif phase_name == \"phase_b\":\n",
    "            # Look for dataset mentions\n",
    "            datasets = re.findall(r'd\\d+', message_content.lower())\n",
    "            if datasets:\n",
    "                return {\"dataset_ids\": datasets}\n",
    "            return {\"dataset_ids\": [\"ds1\", \"ds2\", \"ds3\"]}\n",
    "        elif phase_name == \"phase_c\":\n",
    "            # Look for email and message\n",
    "            email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_content)\n",
    "            email = email_match.group(0) if email_match else \"test@example.com\"\n",
    "            \n",
    "            # Extract message in quotes\n",
    "            msg_match = re.search(r\"'([^']*)'\", message_content)\n",
    "            message = msg_match.group(1) if msg_match else \"Task completed\"\n",
    "            \n",
    "            return {\"notify_email\": email, \"message\": message}\n",
    "        \n",
    "        return {}\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def make_phase_node(defn):\n",
    "    name, req, func = defn[\"name\"], defn[\"required\"], defn[\"function\"]\n",
    "    \n",
    "    def node(state: WorkflowState) -> WorkflowState:\n",
    "        # Get or initialize phase params\n",
    "        if name not in state[\"params\"]:\n",
    "            state[\"params\"][name] = {}\n",
    "        \n",
    "        phase = state[\"params\"][name]\n",
    "        missing = [k for k in req if k not in phase]\n",
    "        \n",
    "        # If missing params, try to extract from original message\n",
    "        if missing:\n",
    "            original_message = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "            extracted = extract_params_from_message(original_message, name)\n",
    "            phase.update(extracted)\n",
    "            \n",
    "            # Check again for missing params after extraction\n",
    "            missing = [k for k in req if k not in phase]\n",
    "            if missing:\n",
    "                state[\"messages\"] += [AIMessage(content=f\"Could not extract {missing} for {name}. Using defaults.\")]\n",
    "                # Set defaults as fallback\n",
    "                if name == \"phase_a\":\n",
    "                    phase.update({\"user_name\": \"DefaultUser\", \"report_type\": \"Standard\"})\n",
    "                elif name == \"phase_b\":\n",
    "                    phase.update({\"dataset_ids\": [\"default_dataset\"]})\n",
    "                elif name == \"phase_c\":\n",
    "                    phase.update({\"notify_email\": \"default@example.com\", \"message\": \"Process completed\"})\n",
    "            else:\n",
    "                state[\"messages\"] += [AIMessage(content=f\"Extracted parameters for {name}: {extracted}\")]\n",
    "        \n",
    "        # Auto-confirm and execute\n",
    "        phase[\"__confirmed__\"] = True\n",
    "        \n",
    "        try:\n",
    "            result = func(phase)\n",
    "            state[\"results\"][name] = result\n",
    "            state[\"messages\"] += [AIMessage(content=f\"Phase {name} completed successfully\")]\n",
    "        except Exception as e:\n",
    "            state[\"messages\"] += [AIMessage(content=f\"Phase {name} failed: {str(e)}\")]\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    return name, node\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(WorkflowState)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "\n",
    "# Add phase nodes\n",
    "for pd in phase_definitions:\n",
    "    builder.add_node(*make_phase_node(pd))\n",
    "\n",
    "# Set up edges\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Each phase goes back to supervisor for next phase determination\n",
    "for pd in phase_definitions:\n",
    "    builder.add_edge(\"supervisor\", pd[\"name\"])\n",
    "    builder.add_edge(pd[\"name\"], \"supervisor\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Test cases\n",
    "tests = [\n",
    "    (\"Run A then B\", [HumanMessage(content=\"Generate report for Bob then analyze datasets d1,d2\")]),\n",
    "    (\"Only C\", [HumanMessage(content=\"Notify user alice@example.com with 'Hello!'\")]),\n",
    "    (\"All phases\", [HumanMessage(content=\"Create report for Sarah, analyze datasets d5,d6,d7, then notify admin@company.com with 'Processing complete'\")]),\n",
    "]\n",
    "\n",
    "for name, msgs in tests:\n",
    "    print(f\"\\n=== Testing: {name} ===\")\n",
    "    state: WorkflowState = {\n",
    "        \"messages\": msgs, \n",
    "        \"params\": {}, \n",
    "        \"results\": {},\n",
    "        \"structured_response\": {\"phases\": [], \"intent\": \"\"},\n",
    "        \"phase_queue\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = graph.invoke(state, {\"configurable\": {\"thread_id\": name}})\n",
    "        print(\"Results:\", json.dumps(res[\"results\"], indent=2))\n",
    "        print(\"Phases executed:\", list(res[\"results\"].keys()))\n",
    "        print(\"Final status:\", [msg.content for msg in res[\"messages\"][-2:]])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1481ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing: Run A then B ===\n",
      "Error: At key 'params': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n",
      "\n",
      "=== Testing: Only C ===\n",
      "Error: At key 'params': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n",
      "\n",
      "=== Testing: All phases ===\n",
      "Error: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<function=SupervisorOut>{\"phases\": [\"phase_a\", \"phase_b\", \"phase_c\"], \"intent\": \"create_report_analyze_notify\"}{\"phase_a\": {\"user_name\": \"Sarah\", \"report_type\": \"report\"}, \"phase_b\": {\"dataset_ids\": [\"d5\", \"d6\", \"d7\"]}, \"phase_c\": {\"notify_email\": \"admin@company.com\", \"message\": \"Processing complete\"}}</function>'}}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime, json, re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "class PhaseAParams(TypedDict): user_name: str; report_type: str\n",
    "class PhaseAResult(TypedDict): status: str; chart_data: List[Dict[str, Any]]\n",
    "class PhaseBParams(TypedDict): dataset_ids: List[str]\n",
    "class PhaseBResult(TypedDict): processed: int; summary: str\n",
    "class PhaseCParams(TypedDict): notify_email: str; message: str\n",
    "class PhaseCResult(TypedDict): sent: bool; timestamp: str\n",
    "\n",
    "class SupervisorOut(TypedDict):\n",
    "    phases: List[Literal['phase_a','phase_b','phase_c']]\n",
    "    intent: str\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    params: Dict[str, Dict[str, Any]]\n",
    "    results: Dict[str, Dict[str, Any]]\n",
    "    structured_response: SupervisorOut\n",
    "    completed_phases: List[str]  # Track what's been done\n",
    "\n",
    "def phase_a_workflow(p: PhaseAParams) -> PhaseAResult:\n",
    "    chart = [{\"x\": i, \"y\": len(p[\"user_name\"]) * i} for i in range(5)]\n",
    "    return {\"status\": f\"Report for {p['user_name']}\", \"chart_data\": chart}\n",
    "\n",
    "def phase_b_workflow(p: PhaseBParams) -> PhaseBResult:\n",
    "    cnt = len(p[\"dataset_ids\"])\n",
    "    return {\"processed\": cnt, \"summary\": f\"{cnt} datasets processed\"}\n",
    "\n",
    "def phase_c_workflow(p: PhaseCParams) -> PhaseCResult:\n",
    "    return {\"sent\": True, \"timestamp\": datetime.datetime.utcnow().isoformat()}\n",
    "\n",
    "phase_definitions = [\n",
    "    {\"name\":\"phase_a\",\"required\":[\"user_name\",\"report_type\"],\"function\":phase_a_workflow},\n",
    "    {\"name\":\"phase_b\",\"required\":[\"dataset_ids\"],\"function\":phase_b_workflow},\n",
    "    {\"name\":\"phase_c\",\"required\":[\"notify_email\",\"message\"],\"function\":phase_c_workflow}\n",
    "]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a supervisor coordinating phases.\"),\n",
    "    SystemMessage(content=\"Available phases: phase_a (user_name,report_type), phase_b (dataset_ids), phase_c (notify_email,message).\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    SystemMessage(content=\"Return JSON matching SupervisorOut: {'phases':[...], 'intent': '...'}\")\n",
    "])\n",
    "supervisor_llm = llm.with_structured_output(SupervisorOut)\n",
    "\n",
    "def extract_params(message_content: str, phase_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract parameters from user message\"\"\"\n",
    "    content = message_content.lower()\n",
    "    \n",
    "    if phase_name == \"phase_a\":\n",
    "        # Extract user name and report type\n",
    "        user_name = \"TestUser\"\n",
    "        if \"bob\" in content:\n",
    "            user_name = \"Bob\"\n",
    "        elif \"sarah\" in content:\n",
    "            user_name = \"Sarah\"\n",
    "        \n",
    "        report_type = \"Monthly\"\n",
    "        if \"custom\" in content:\n",
    "            report_type = \"Custom\"\n",
    "        elif \"daily\" in content:\n",
    "            report_type = \"Daily\"\n",
    "            \n",
    "        return {\"user_name\": user_name, \"report_type\": report_type}\n",
    "    \n",
    "    elif phase_name == \"phase_b\":\n",
    "        # Extract dataset IDs\n",
    "        datasets = re.findall(r'd\\d+', content)\n",
    "        if not datasets:\n",
    "            datasets = [\"ds1\", \"ds2\", \"ds3\"]\n",
    "        return {\"dataset_ids\": datasets}\n",
    "    \n",
    "    elif phase_name == \"phase_c\":\n",
    "        # Extract email and message\n",
    "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_content)\n",
    "        email = email_match.group(0) if email_match else \"test@example.com\"\n",
    "        \n",
    "        msg_match = re.search(r\"'([^']*)'\", message_content)\n",
    "        message = msg_match.group(1) if msg_match else \"Task completed\"\n",
    "        \n",
    "        return {\"notify_email\": email, \"message\": message}\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def supervisor_node(state: WorkflowState) -> Command[Literal['phase_a','phase_b','phase_c', END]]:\n",
    "    # First time - plan the phases\n",
    "    if \"structured_response\" not in state or not state[\"structured_response\"][\"phases\"]:\n",
    "        # Use the prompt template properly\n",
    "        prompt_input = supervisor_prompt.invoke({\"messages\": state[\"messages\"]})\n",
    "        resp = supervisor_llm.invoke(prompt_input)\n",
    "        state[\"structured_response\"] = resp\n",
    "        state[\"completed_phases\"] = []\n",
    "        state[\"messages\"] += [AIMessage(content=f\"Planning phases: {resp['phases']}\")]\n",
    "    \n",
    "    # Find next phase to execute\n",
    "    planned_phases = state[\"structured_response\"][\"phases\"]\n",
    "    completed = state.get(\"completed_phases\", [])\n",
    "    \n",
    "    # Find first unfinished phase\n",
    "    for phase in planned_phases:\n",
    "        if phase not in completed:\n",
    "            return Command(goto=phase)\n",
    "    \n",
    "    # All phases done\n",
    "    state[\"messages\"] += [AIMessage(content=\"All phases completed!\")]\n",
    "    return Command(goto=END)\n",
    "\n",
    "def make_phase_node(defn):\n",
    "    name, req, func = defn[\"name\"], defn[\"required\"], defn[\"function\"]\n",
    "    \n",
    "    def node(state: WorkflowState) -> WorkflowState:\n",
    "        # Initialize params if needed\n",
    "        if name not in state[\"params\"]:\n",
    "            state[\"params\"][name] = {}\n",
    "        \n",
    "        phase = state[\"params\"][name]\n",
    "        missing = [k for k in req if k not in phase]\n",
    "        \n",
    "        # If missing params, try to extract from original message\n",
    "        if missing:\n",
    "            original_msg = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "            extracted = extract_params(original_msg, name)\n",
    "            phase.update(extracted)\n",
    "            state[\"messages\"] += [AIMessage(content=f\"Extracted params for {name}: {extracted}\")]\n",
    "        \n",
    "        # Auto-confirm and execute\n",
    "        phase[\"__confirmed__\"] = True\n",
    "        \n",
    "        try:\n",
    "            # Execute the phase function\n",
    "            result = func(phase)\n",
    "            state[\"results\"][name] = result\n",
    "            \n",
    "            # Mark as completed\n",
    "            if \"completed_phases\" not in state:\n",
    "                state[\"completed_phases\"] = []\n",
    "            state[\"completed_phases\"].append(name)\n",
    "            \n",
    "            state[\"messages\"] += [AIMessage(content=f\"Phase {name} completed successfully\")]\n",
    "            \n",
    "        except Exception as e:\n",
    "            state[\"messages\"] += [AIMessage(content=f\"Phase {name} failed: {str(e)}\")]\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    return name, node\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(WorkflowState)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "\n",
    "# Add phase nodes\n",
    "for pd in phase_definitions:\n",
    "    builder.add_node(*make_phase_node(pd))\n",
    "\n",
    "# Set up edges\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Each phase goes back to supervisor for next phase determination\n",
    "for pd in phase_definitions:\n",
    "    builder.add_edge(\"supervisor\", pd[\"name\"])\n",
    "    builder.add_edge(pd[\"name\"], \"supervisor\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Test cases\n",
    "tests = [\n",
    "    (\"Run A then B\", [HumanMessage(content=\"Generate report for Bob then analyze datasets d1,d2\")]),\n",
    "    (\"Only C\", [HumanMessage(content=\"Notify user alice@example.com with 'Hello!'\")]),\n",
    "    (\"All phases\", [HumanMessage(content=\"Create report for Sarah, analyze datasets d5,d6,d7, then notify admin@company.com with 'Processing complete'\")]),\n",
    "]\n",
    "\n",
    "for name, msgs in tests:\n",
    "    print(f\"\\n=== Testing: {name} ===\")\n",
    "    state: WorkflowState = {\n",
    "        \"messages\": msgs, \n",
    "        \"params\": {}, \n",
    "        \"results\": {},\n",
    "        \"structured_response\": {\"phases\": [], \"intent\": \"\"},\n",
    "        \"completed_phases\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = graph.invoke(state, {\"configurable\": {\"thread_id\": name}})\n",
    "        print(\"Results:\", json.dumps(res[\"results\"], indent=2))\n",
    "        print(\"Completed phases:\", res.get(\"completed_phases\", []))\n",
    "        print(\"Final messages:\", [msg.content for msg in res[\"messages\"][-2:]])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714fea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing: Run A then B ===\n",
      "Error: Error code: 500 - {'error': {'message': 'Internal Server Error', 'type': 'internal_server_error'}}\n",
      "\n",
      "=== Testing: Only C ===\n",
      "Error: At key 'completed_phases': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n",
      "\n",
      "=== Testing: All phases ===\n",
      "Error: At key 'completed_phases': Can receive only one value per step. Use an Annotated key to handle multiple values.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime, json, re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "class PhaseAParams(TypedDict): user_name: str; report_type: str\n",
    "class PhaseAResult(TypedDict): status: str; chart_data: List[Dict[str, Any]]\n",
    "class PhaseBParams(TypedDict): dataset_ids: List[str]\n",
    "class PhaseBResult(TypedDict): processed: int; summary: str\n",
    "class PhaseCParams(TypedDict): notify_email: str; message: str\n",
    "class PhaseCResult(TypedDict): sent: bool; timestamp: str\n",
    "\n",
    "class SupervisorOut(TypedDict):\n",
    "    phases: List[Literal['phase_a','phase_b','phase_c']]\n",
    "    intent: str\n",
    "\n",
    "# Reducer function for merging nested dictionaries\n",
    "def merge_nested_dicts(existing: Dict[str, Dict[str, Any]], update: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
    "    if existing is None:\n",
    "        existing = {}\n",
    "    if update is None:\n",
    "        return existing\n",
    "    \n",
    "    result = existing.copy()\n",
    "    for key, value in update.items():\n",
    "        if key in result:\n",
    "            result[key].update(value)\n",
    "        else:\n",
    "            result[key] = value\n",
    "    return result\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    params: Annotated[Dict[str, Dict[str, Any]], merge_nested_dicts]\n",
    "    results: Annotated[Dict[str, Dict[str, Any]], merge_nested_dicts]\n",
    "    structured_response: SupervisorOut\n",
    "    completed_phases: List[str]  # Track what's been done\n",
    "\n",
    "def phase_a_workflow(p: PhaseAParams) -> PhaseAResult:\n",
    "    chart = [{\"x\": i, \"y\": len(p[\"user_name\"]) * i} for i in range(5)]\n",
    "    return {\"status\": f\"Report for {p['user_name']}\", \"chart_data\": chart}\n",
    "\n",
    "def phase_b_workflow(p: PhaseBParams) -> PhaseBResult:\n",
    "    cnt = len(p[\"dataset_ids\"])\n",
    "    return {\"processed\": cnt, \"summary\": f\"{cnt} datasets processed\"}\n",
    "\n",
    "def phase_c_workflow(p: PhaseCParams) -> PhaseCResult:\n",
    "    return {\"sent\": True, \"timestamp\": datetime.datetime.utcnow().isoformat()}\n",
    "\n",
    "phase_definitions = [\n",
    "    {\"name\":\"phase_a\",\"required\":[\"user_name\",\"report_type\"],\"function\":phase_a_workflow},\n",
    "    {\"name\":\"phase_b\",\"required\":[\"dataset_ids\"],\"function\":phase_b_workflow},\n",
    "    {\"name\":\"phase_c\",\"required\":[\"notify_email\",\"message\"],\"function\":phase_c_workflow}\n",
    "]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a supervisor that decides which phases to execute based on user requests.\"),\n",
    "    SystemMessage(content=\"\"\"Available phases:\n",
    "- phase_a: Generate reports (needs user_name, report_type)  \n",
    "- phase_b: Analyze datasets (needs dataset_ids)\n",
    "- phase_c: Send notifications (needs notify_email, message)\n",
    "\n",
    "Analyze the user's request and determine which phases should be executed in order.\"\"\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    SystemMessage(content=\"Respond with ONLY valid JSON in this exact format: {\\\"phases\\\": [\\\"phase_a\\\"], \\\"intent\\\": \\\"description\\\"}. No additional text.\")\n",
    "])\n",
    "supervisor_llm = llm.with_structured_output(SupervisorOut)\n",
    "\n",
    "def extract_params(message_content: str, phase_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract parameters from user message\"\"\"\n",
    "    content = message_content.lower()\n",
    "    \n",
    "    if phase_name == \"phase_a\":\n",
    "        # Extract user name and report type\n",
    "        user_name = \"TestUser\"\n",
    "        if \"bob\" in content:\n",
    "            user_name = \"Bob\"\n",
    "        elif \"sarah\" in content:\n",
    "            user_name = \"Sarah\"\n",
    "        \n",
    "        report_type = \"Monthly\"\n",
    "        if \"custom\" in content:\n",
    "            report_type = \"Custom\"\n",
    "        elif \"daily\" in content:\n",
    "            report_type = \"Daily\"\n",
    "            \n",
    "        return {\"user_name\": user_name, \"report_type\": report_type}\n",
    "    \n",
    "    elif phase_name == \"phase_b\":\n",
    "        # Extract dataset IDs\n",
    "        datasets = re.findall(r'd\\d+', content)\n",
    "        if not datasets:\n",
    "            datasets = [\"ds1\", \"ds2\", \"ds3\"]\n",
    "        return {\"dataset_ids\": datasets}\n",
    "    \n",
    "    elif phase_name == \"phase_c\":\n",
    "        # Extract email and message\n",
    "        email_match = re.search(r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+', message_content)\n",
    "        email = email_match.group(0) if email_match else \"test@example.com\"\n",
    "        \n",
    "        msg_match = re.search(r\"'([^']*)'\", message_content)\n",
    "        message = msg_match.group(1) if msg_match else \"Task completed\"\n",
    "        \n",
    "        return {\"notify_email\": email, \"message\": message}\n",
    "    \n",
    "    return {}\n",
    "\n",
    "def supervisor_node(state: WorkflowState) -> Command[Literal['phase_a','phase_b','phase_c', END]]:\n",
    "    # First time - plan the phases\n",
    "    if \"structured_response\" not in state or not state[\"structured_response\"][\"phases\"]:\n",
    "        # Use the prompt template properly\n",
    "        prompt_input = supervisor_prompt.invoke({\"messages\": state[\"messages\"]})\n",
    "        resp = supervisor_llm.invoke(prompt_input)\n",
    "        \n",
    "        return Command(\n",
    "            update={\n",
    "                \"structured_response\": resp,\n",
    "                \"completed_phases\": [],\n",
    "                \"messages\": [AIMessage(content=f\"Planning phases: {resp['phases']}\")]\n",
    "            },\n",
    "            goto=resp[\"phases\"][0] if resp[\"phases\"] else END\n",
    "        )\n",
    "    \n",
    "    # Find next phase to execute\n",
    "    planned_phases = state[\"structured_response\"][\"phases\"]\n",
    "    completed = state.get(\"completed_phases\", [])\n",
    "    \n",
    "    # Find first unfinished phase\n",
    "    for phase in planned_phases:\n",
    "        if phase not in completed:\n",
    "            return Command(goto=phase)\n",
    "    \n",
    "    # All phases done\n",
    "    return Command(\n",
    "        update={\"messages\": [AIMessage(content=\"All phases completed!\")]},\n",
    "        goto=END\n",
    "    )\n",
    "\n",
    "def make_phase_node(defn):\n",
    "    name, req, func = defn[\"name\"], defn[\"required\"], defn[\"function\"]\n",
    "    \n",
    "    def node(state: WorkflowState) -> Dict[str, Any]:\n",
    "        # Get current params for this phase\n",
    "        current_params = state.get(\"params\", {}).get(name, {}).copy()\n",
    "        missing = [k for k in req if k not in current_params]\n",
    "        \n",
    "        # If missing params, try to extract from original message\n",
    "        if missing:\n",
    "            original_msg = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "            extracted = extract_params(original_msg, name)\n",
    "            current_params.update(extracted)\n",
    "        \n",
    "        # Auto-confirm\n",
    "        current_params[\"__confirmed__\"] = True\n",
    "        \n",
    "        # Prepare the update dictionary\n",
    "        update_dict = {\n",
    "            \"params\": {name: current_params},\n",
    "            \"messages\": [AIMessage(content=f\"Extracted params for {name}: {current_params}\")]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Execute the phase function\n",
    "            result = func(current_params)\n",
    "            \n",
    "            # Mark as completed\n",
    "            completed = state.get(\"completed_phases\", []).copy()\n",
    "            completed.append(name)\n",
    "            \n",
    "            update_dict.update({\n",
    "                \"results\": {name: result},\n",
    "                \"completed_phases\": completed,\n",
    "            })\n",
    "            update_dict[\"messages\"].append(AIMessage(content=f\"Phase {name} completed successfully\"))\n",
    "            \n",
    "        except Exception as e:\n",
    "            update_dict[\"messages\"].append(AIMessage(content=f\"Phase {name} failed: {str(e)}\"))\n",
    "        \n",
    "        return update_dict\n",
    "    \n",
    "    return name, node\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(WorkflowState)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "\n",
    "# Add phase nodes\n",
    "for pd in phase_definitions:\n",
    "    builder.add_node(*make_phase_node(pd))\n",
    "\n",
    "# Set up edges\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Each phase goes back to supervisor for next phase determination\n",
    "for pd in phase_definitions:\n",
    "    builder.add_edge(\"supervisor\", pd[\"name\"])\n",
    "    builder.add_edge(pd[\"name\"], \"supervisor\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Test cases\n",
    "tests = [\n",
    "    (\"Run A then B\", [HumanMessage(content=\"Generate report for Bob then analyze datasets d1,d2\")]),\n",
    "    (\"Only C\", [HumanMessage(content=\"Notify user alice@example.com with 'Hello!'\")]),\n",
    "    (\"All phases\", [HumanMessage(content=\"Create report for Sarah, analyze datasets d5,d6,d7, then notify admin@company.com with 'Processing complete'\")]),\n",
    "]\n",
    "\n",
    "for name, msgs in tests:\n",
    "    print(f\"\\n=== Testing: {name} ===\")\n",
    "    state: WorkflowState = {\n",
    "        \"messages\": msgs, \n",
    "        \"params\": {}, \n",
    "        \"results\": {},\n",
    "        \"structured_response\": {\"phases\": [], \"intent\": \"\"},\n",
    "        \"completed_phases\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        res = graph.invoke(state, {\"configurable\": {\"thread_id\": name}})\n",
    "        print(\"Results:\", json.dumps(res[\"results\"], indent=2))\n",
    "        print(\"Completed phases:\", res.get(\"completed_phases\", []))\n",
    "        print(\"Final messages:\", [msg.content for msg in res[\"messages\"][-2:]])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1782d885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running test scenario: Run A then B =====\n",
      "[DEBUG] Supervisor received messages: [HumanMessage(content='Generate report for Bob then analyze datasets d1,d2', additional_kwargs={}, response_metadata={}, id='a3ac94f8-adcf-4291-ac32-04db5aa8428f')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 122\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===== Running test scenario: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m =====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    121\u001b[0m state: WorkflowState \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: msgs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}}\n\u001b[1;32m--> 122\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mname\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__interrupt__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Graph interrupted; messages to user: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2142\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2141\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2143\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2144\u001b[0m     config,\n\u001b[0;32m   2145\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2146\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2147\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2148\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2149\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2151\u001b[0m ):\n\u001b[0;32m   2152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2153\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1797\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1797\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1798\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1799\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1800\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1801\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1802\u001b[0m         ):\n\u001b[0;32m   1803\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m )\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 310\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[12], line 77\u001b[0m, in \u001b[0;36msupervisor_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msupervisor_node\u001b[39m(state: WorkflowState) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Command[Literal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_a\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_b\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase_c\u001b[39m\u001b[38;5;124m'\u001b[39m, END]]:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Supervisor received messages: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43msupervisor_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] Supervisor structured output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_response\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m resp\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langchain_core\\runnables\\base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5356\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5358\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5361\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5362\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5363\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5364\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:285\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m--> 285\u001b[0m             [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[0;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:271\u001b[0m, in \u001b[0;36mBaseChatModel._convert_input\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m     )\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid input type <class 'dict'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "def ask_json(prompt: str) -> Dict[str, Any]:\n",
    "    print(f\"[DEBUG] LLM JSON prompt:\\n{prompt}\")\n",
    "    resp = llm.invoke(ChatPromptTemplate.from_template(prompt)).content\n",
    "    print(f\"[DEBUG] LLM JSON raw response:\\n{resp}\")\n",
    "    parsed = JsonOutputParser().parse(resp)\n",
    "    print(f\"[DEBUG] Parsed JSON:\\n{parsed}\")\n",
    "    return parsed\n",
    "\n",
    "class PhaseAParams(TypedDict): user_name: str; report_type: str\n",
    "class PhaseAResult(TypedDict): status: str; chart_data: List[Dict[str, Any]]\n",
    "class PhaseBParams(TypedDict): dataset_ids: List[str]\n",
    "class PhaseBResult(TypedDict): processed: int; summary: str\n",
    "class PhaseCParams(TypedDict): notify_email: str; message: str\n",
    "class PhaseCResult(TypedDict): sent: bool; timestamp: str\n",
    "\n",
    "class SupervisorOut(TypedDict):\n",
    "    phases: List[Literal['phase_a','phase_b','phase_c']]\n",
    "    intent: str\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    params: Dict[str, Dict[str, Any]]\n",
    "    results: Dict[str, Dict[str, Any]]\n",
    "    structured_response: SupervisorOut\n",
    "\n",
    "def phase_a_workflow(p: PhaseAParams) -> PhaseAResult:\n",
    "    print(f\"[DEBUG] Executing phase_a_workflow with params: {p}\")\n",
    "    chart = [{\"x\": i, \"y\": len(p[\"user_name\"]) * i} for i in range(5)]\n",
    "    result = {\"status\": f\"Report for {p['user_name']}\", \"chart_data\": chart}\n",
    "    print(f\"[DEBUG] phase_a result: {result}\")\n",
    "    return result\n",
    "\n",
    "def phase_b_workflow(p: PhaseBParams) -> PhaseBResult:\n",
    "    print(f\"[DEBUG] Executing phase_b_workflow with params: {p}\")\n",
    "    cnt = len(p[\"dataset_ids\"])\n",
    "    result = {\"processed\": cnt, \"summary\": f\"{cnt} datasets processed\"}\n",
    "    print(f\"[DEBUG] phase_b result: {result}\")\n",
    "    return result\n",
    "\n",
    "def phase_c_workflow(p: PhaseCParams) -> PhaseCResult:\n",
    "    print(f\"[DEBUG] Executing phase_c_workflow with params: {p}\")\n",
    "    res = {\"sent\": True, \"timestamp\": datetime.datetime.utcnow().isoformat()}\n",
    "    print(f\"[DEBUG] phase_c result: {res}\")\n",
    "    return res\n",
    "\n",
    "phase_definitions = [\n",
    "    {\"name\":\"phase_a\",\"required\":[\"user_name\",\"report_type\"],\"function\":phase_a_workflow},\n",
    "    {\"name\":\"phase_b\",\"required\":[\"dataset_ids\"],\"function\":phase_b_workflow},\n",
    "    {\"name\":\"phase_c\",\"required\":[\"notify_email\",\"message\"],\"function\":phase_c_workflow}\n",
    "]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a supervisor coordinating phases.\"),\n",
    "    SystemMessage(content=\"Available phases: phase_a (user_name,report_type), phase_b (dataset_ids), phase_c (notify_email,message).\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    SystemMessage(content=\"Return JSON matching SupervisorOut: {'phases':[...], 'intent':'...'}\")\n",
    "])\n",
    "supervisor_llm = llm.with_structured_output(SupervisorOut)\n",
    "\n",
    "def supervisor_node(state: WorkflowState) -> Command[Literal['phase_a','phase_b','phase_c', END]]:\n",
    "    print(f\"[DEBUG] Supervisor received messages: {state['messages']}\")\n",
    "    resp = supervisor_llm.invoke({\"messages\": state[\"messages\"]}, config={\"configurable\":{\"session_id\":\"sup\"}})\n",
    "    print(f\"[DEBUG] Supervisor structured output: {resp}\")\n",
    "    state[\"structured_response\"] = resp\n",
    "    chosen = resp[\"phases\"][0] if resp[\"phases\"] else END\n",
    "    print(f\"[DEBUG] Supervisor routing to: {chosen}\")\n",
    "    return Command(goto=chosen)\n",
    "\n",
    "def make_phase_node(defn):\n",
    "    name, req, func = defn[\"name\"], defn[\"required\"], defn[\"function\"]\n",
    "    def node(state: WorkflowState) -> WorkflowState:\n",
    "        print(f\"[DEBUG] Entered node {name}, current params: {state['params'].get(name)}\")\n",
    "        phase = state[\"params\"].setdefault(name, {})\n",
    "        missing = [k for k in req if k not in phase]\n",
    "        if missing:\n",
    "            print(f\"[DEBUG] {name} missing fields: {missing}\")\n",
    "            return {\"messages\":[AIMessage(content=f\"Please provide {missing} for {name}\")]}\n",
    "        if \"__confirmed__\" not in phase:\n",
    "            print(f\"[DEBUG] {name} awaiting confirmation: {phase}\")\n",
    "            return {\"messages\":[AIMessage(content=f\"Confirm {name}? yes/no\")]}\n",
    "        print(f\"[DEBUG] {name} all set, running workflow function\")\n",
    "        state[\"results\"][name] = func(phase)\n",
    "        return state\n",
    "    return name, node\n",
    "\n",
    "builder = StateGraph(WorkflowState)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "for pd in phase_definitions:\n",
    "    builder.add_node(*make_phase_node(pd))\n",
    "\n",
    "builder.add_edge(START,\"supervisor\")\n",
    "for pd in phase_definitions:\n",
    "    builder.add_edge(\"supervisor\", pd[\"name\"])\n",
    "    builder.add_edge(pd[\"name\"], \"supervisor\")\n",
    "builder.add_edge(phase_definitions[-1][\"name\"], END)\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "tests = [\n",
    "    (\"Run A then B\", [HumanMessage(content=\"Generate report for Bob then analyze datasets d1,d2\")]),\n",
    "    (\"Only C\", [HumanMessage(content=\"Notify user alice@example.com with 'Hello!'\")]),\n",
    "]\n",
    "\n",
    "for name, msgs in tests:\n",
    "    print(f\"\\n===== Running test scenario: {name} =====\")\n",
    "    state: WorkflowState = {\"messages\": msgs, \"params\": {}, \"results\": {}}\n",
    "    res = graph.invoke(state, {\"configurable\":{\"thread_id\":name}})\n",
    "    while \"__interrupt__\" in res:\n",
    "        print(f\"[DEBUG] Graph interrupted; messages to user: {res.get('messages')}\")\n",
    "        res = graph.invoke(res, {\"configurable\":{\"thread_id\":name}})\n",
    "    print(f\"[DEBUG] Final results for {name}:\")\n",
    "    print(json.dumps(res[\"results\"], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30292811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test A->B {}\n",
      "Test C only {}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "import datetime, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "class PhaseAParams(TypedDict): user_name: str; report_type: str\n",
    "class PhaseAResult(TypedDict): status: str; chart_data: List[Dict[str,Any]]\n",
    "class PhaseBParams(TypedDict): dataset_ids: List[str]\n",
    "class PhaseBResult(TypedDict): processed: int; summary: str\n",
    "class PhaseCParams(TypedDict): notify_email: str; message: str\n",
    "class PhaseCResult(TypedDict): sent: bool; timestamp: str\n",
    "\n",
    "class SupervisorOut(TypedDict):\n",
    "    next_phase: Literal['phase_a','phase_b','phase_c']\n",
    "    intent: str\n",
    "\n",
    "class WorkflowState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    params: Dict[str, Dict[str,Any]]\n",
    "    results: Dict[str, Dict[str,Any]]\n",
    "    supervisor_out: SupervisorOut\n",
    "\n",
    "def ask_json(prompt: str) -> Dict[str, Any]:\n",
    "    return JsonOutputParser().parse(llm.invoke(ChatPromptTemplate.from_template(prompt)).content)\n",
    "\n",
    "def phase_a_workflow(p: PhaseAParams) -> PhaseAResult:\n",
    "    chart = [{\"x\": i, \"y\": len(p[\"user_name\"])*i} for i in range(5)]\n",
    "    return {\"status\": f\"Report for {p['user_name']}\", \"chart_data\": chart}\n",
    "\n",
    "def phase_b_workflow(p: PhaseBParams) -> PhaseBResult:\n",
    "    cnt = len(p[\"dataset_ids\"])\n",
    "    return {\"processed\": cnt, \"summary\": f\"{cnt} datasets processed\"}\n",
    "\n",
    "def phase_c_workflow(p: PhaseCParams) -> PhaseCResult:\n",
    "    return {\"sent\": True, \"timestamp\": datetime.datetime.utcnow().isoformat()}\n",
    "\n",
    "phase_defs = [\n",
    "    {\"name\":\"phase_a\",\"required\":[\"user_name\",\"report_type\"],\"workflow\":phase_a_workflow},\n",
    "    {\"name\":\"phase_b\",\"required\":[\"dataset_ids\"],\"workflow\":phase_b_workflow},\n",
    "    {\"name\":\"phase_c\",\"required\":[\"notify_email\",\"message\"],\"workflow\":phase_c_workflow},\n",
    "]\n",
    "\n",
    "supervisor_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"Decide which phase to start based on user intent.\"),\n",
    "    SystemMessage(content=\"Options: phase_a, phase_b, phase_c\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "    SystemMessage(content=\"Return JSON: {'next_phase': <phase>, 'intent': <summary>}\")\n",
    "])\n",
    "\n",
    "# Create a chain that combines the prompt with the structured output\n",
    "supervisor_chain = supervisor_prompt | llm.with_structured_output(SupervisorOut)\n",
    "\n",
    "def supervisor_node(state: WorkflowState) -> Command:\n",
    "    # Use the chain to properly format the prompt and get structured output\n",
    "    out = supervisor_chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    print(out)\n",
    "    state[\"supervisor_out\"] = out\n",
    "    return Command(goto=out[\"next_phase\"])\n",
    "\n",
    "def make_phase_node(defn):\n",
    "    name = defn[\"name\"]; req = defn[\"required\"]; wf = defn[\"workflow\"]\n",
    "    def node(state: WorkflowState) -> WorkflowState:\n",
    "        phase = state[\"params\"].setdefault(name,{})\n",
    "        missing = [k for k in req if k not in phase]\n",
    "        if missing:\n",
    "            return {\"messages\":[AIMessage(content=f\"Provide {missing} for {name}\")]}\n",
    "        if \"__confirmed__\" not in phase:\n",
    "            return {\"messages\":[AIMessage(content=f\"Confirm {name}? yes/no\")]}\n",
    "        state[\"results\"][name] = wf(phase)\n",
    "        return state\n",
    "    return name, node\n",
    "\n",
    "builder = StateGraph(WorkflowState)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "for pd in phase_defs:\n",
    "    builder.add_node(*make_phase_node(pd))\n",
    "builder.add_edge(START,\"supervisor\")\n",
    "for pd in phase_defs:\n",
    "    builder.add_edge(pd[\"name\"], END) \n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "tests = [\n",
    "    (\"Test A->B\", [HumanMessage(content=\"Create report for John then analyze data\")]),\n",
    "    (\"Test C only\", [HumanMessage(content=\"Send notification to x@x.com\")]),\n",
    "]\n",
    "\n",
    "for name, msgs in tests:\n",
    "    state = {\"messages\": msgs, \"params\": {}, \"results\": {}}\n",
    "    res = graph.invoke(state, {\"configurable\":{\"thread_id\":name}})\n",
    "    while \"__interrupt__\" in res:\n",
    "        res = graph.invoke(res, {\"configurable\":{\"thread_id\":name}})\n",
    "    print(name, json.dumps(res[\"results\"], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
